#!/usr/bin/python
# -*- coding: ascii -*-

import requests
from bs4 import BeautifulSoup

proxy_list = ["http://www.httptunnel.ge/ProxyListForFree.aspx"]
fname = "proxies/proxies.txt"
mydivs = 0


def proxy_scan():
    print("starting proxy scan..")
    print("""_____________$$________________________$$$$
____________$$_____________________________$$
___________$__________________________________$$
___________$$___________________________________$$
__________$$__$$______________________$$__________$$
________$$__$$___$$$$_________$$$$____$$__________$$$$
______$$___$$__$$$$__$$_____$$$$__$$_$$_____________$$$
______$$___$$____$$$$_________$$$$___$$_______________$$
______$$___$$________________________$$_______________$$
______$$____$$_______________________$$___woof nigga__________$$
________$$__$$____$$$$$$_____________$$___________$$$
________$$__$$__$$______$$___________$$_________$$
________$$__$$__$$______$$___________$$_______$$
__________$$$$____$$$$$$_____________$$$$____$$$$
__________$$$$_____________________$$__$$____$$$
___________$$_$$$$$$$$$$$$_____$$$$______$$$$_$$
_____________$$___$$______$$$$$_______________$$
_____________$$_____$$$$$$$__________//__________$$
_____________$$___//________________//___________$$
____________$$____//_______________//_____________$$
____________$$______//_____________//_____its the bling bling doge_________$$
____________$$_________//_+_____+_//__________________$
____________$$____________+_____+_________________$$
__________$$______________+=====+___________$$___________$
__________$$__________$$___________$$_____________$$
________$$__$$________$$__$$__$$__$$_______________$$
______$$____$$__________$$_______$$_______________$$
______$$____$$____________$$___$$_________________$$
____$$______$$_____________$$_$$_______$$_________$$
____$$______$$________$$____$$$________$$_________$$
____$$______$$________$$____$$$_______$$__________$$
____$$______$$________$$_______________$$__________$$
____$$______$$________$$_______________$$____________$
_$$$$_______$$________$$_______________$$____________$$
$___$$______$$________$$$$___________$$$$____________$$
$___$$______$$________$$__$$_______$$__$$____________$$
_$$$$$______$$________$$____$$___$$_____$$___________$$
____$$______$$________$$______$$_______$$___________$$
____$$______$$________$$_____$$________$$___________$$
__$$________$$________$$$$$$$$___$$$$$$__$$_________$$
__$$________$$________$$______$$$______$$$$_________$$
$$________$$__________$$_________$$$$$$__$$__________$
$$______$$__________$$$$$$$$$$$$$$$______$$__________$
$$_$$_$$$__________$$_____________$$$$$$$__$$_________$
_$$$$$$$___________$$______________________$$________$$
_____$$__$$__$$__$$_$______________________$$__________$$
______$$$$__$___$__$$______________________$$____________$
_______$$___$___$__$________________________$$_$__$$__$$__$
_________$$$$$$$$$$__________________________$$_$_$$$$$$$$""")

    r = requests.get(proxy_list[0])

    if (r.status_code == 200):
        html_page = r.text
        soup = BeautifulSoup(html_page, 'html.parser')
        #print(soup.prettify())


        mydivs = soup.findAll("a", {"target": "_new"})


        for i in range(len(mydivs)):
            x = mydivs[i]

            print(x.text)

            write_to_file(x.text)

    else:
        print("server down trying another..")
        # call function but +1 proxy_list so it is next website



def write_to_file(ipport):

    try:
        with open(fname, 'a+') as f:
            f.write(ipport + "\n")

    except:
        print("Error")



proxy_scan()
